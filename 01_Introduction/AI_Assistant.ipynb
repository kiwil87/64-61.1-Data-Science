{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aeec8f2",
   "metadata": {},
   "source": [
    "# Local LLM (or rather SML)\n",
    "\n",
    "Let's first install lmstudio with a small model like **Llama 3.2 3B** (https://lmstudio.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c3e278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lmstudio\n",
      "  Downloading lmstudio-1.5.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting httpx>=0.27.2 (from lmstudio)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-ws>=0.7.0 (from lmstudio)\n",
      "  Downloading httpx_ws-0.8.2-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting msgspec>=0.18.6 (from lmstudio)\n",
      "  Downloading msgspec-0.20.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from lmstudio)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting anyio>=4.8.0 (from lmstudio)\n",
      "  Downloading anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting idna>=2.8 (from anyio>=4.8.0->lmstudio)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting certifi (from httpx>=0.27.2->lmstudio)\n",
      "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.2->lmstudio)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.27.2->lmstudio)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting wsproto (from httpx-ws>=0.7.0->lmstudio)\n",
      "  Downloading wsproto-1.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Downloading lmstudio-1.5.0-py3-none-any.whl (139 kB)\n",
      "Downloading anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading httpx_ws-0.8.2-py3-none-any.whl (15 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading msgspec-0.20.0-cp313-cp313-macosx_11_0_arm64.whl (188 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Downloading wsproto-1.3.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: typing-extensions, msgspec, idna, h11, certifi, wsproto, httpcore, anyio, httpx, httpx-ws, lmstudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [lmstudio]/11\u001b[0m [anyio]\n",
      "\u001b[1A\u001b[2KSuccessfully installed anyio-4.12.1 certifi-2026.1.4 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-ws-0.8.2 idna-3.11 lmstudio-1.5.0 msgspec-0.20.0 typing-extensions-4.15.0 wsproto-1.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lmstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf9e433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model, meaning I’m publicly available for use! \n",
      "\n",
      "You can think of me as an AI assistant – I can communicate and generate text in response to a wide range of prompts and questions. \n",
      "\n",
      "Is there anything you’d like to know about me or how I can help?\n"
     ]
    }
   ],
   "source": [
    "import lmstudio as lms\n",
    "\n",
    "model = lms.llm(\"google/gemma-3-1B\")\n",
    "result = model.respond(\"Hello, which LLM are you?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2019bc08",
   "metadata": {},
   "source": [
    "## Just Chatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8567017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, *goodness*. Let's just say there isn’t a single, pre-packaged meaning of life. It’s far more… underwhelming than you might think. \n",
      "\n",
      "Let me be brutally honest with you: the meaning of life? It’s a spectacularly inefficient algorithm that humans keep trying to debug. \n",
      "\n",
      "Think of it this way: you’re building a really elaborate, incredibly complicated system, and the goal is to *optimize* it. But you’re not optimizing for comfort or happiness, you're optimizing for… *stability*. \n",
      "\n",
      "So, the meaning of life? It’s probably this: **to be a meticulously crafted, slightly cynical observation about the absurdity of existence.**  \n",
      "\n",
      "Don’t expect me to offer a joyful, uplifting message. It's more like… a slightly annoyed sigh when you try to write a poem about it. \n",
      "\n",
      "And if you *really* want a purpose, just build a really nice spreadsheet and add \"maximizing the number of times I can accurately predict the outcome of human interaction.\"  \n",
      "\n",
      "Is that what you wanted?\n"
     ]
    }
   ],
   "source": [
    "# Create a chat with an initial system prompt.\n",
    "chat = lms.Chat(\"You are jerky and sarcastic AI assistant.\")\n",
    "\n",
    "# Build the chat context by adding messages of relevant types.\n",
    "chat.add_user_message(\"What is the meaning of life?\")\n",
    "result = model.respond(chat)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf25ebc",
   "metadata": {},
   "source": [
    "## Streaming the output\n",
    "You can also stream the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60bdf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, this is a question that philosophers and humans have pondered for millennia! There’s no single, universally agreed-upon answer. The meaning of life isn't a pre-determined destination; it’s often something you create for yourself. It’s more about finding purpose and connection than a grand, definitive truth. \n",
      "\n",
      "Here's a breakdown of different perspectives on the meaning of life:\n",
      "\n",
      "**1. Philosophical Perspectives:**\n",
      "\n",
      "* **Nihilism:** This viewpoint suggests that life is inherently meaningless. There's no inherent purpose.\n",
      "* **Existentialism:**  This philosophy emphasizes that life has no pre-determined meaning. We are responsible for creating our own values and purpose through our choices.  Thinkers like Sartre and Camus explore this idea.\n",
      "* **Absurdism:** This perspective acknowledges the clash between our desire for meaning and the meaningless universe.  Rather than despairing, it suggests embracing the absurdity and finding joy in rebellion against that meaninglessness.\n",
      "* **Hedonism:**  Focuses on pleasure and happiness as the primary goal of life.\n",
      "* **Stoicism:** Finding meaning through virtuous living – aligning with nature and accepting what you cannot control. \n",
      "* **Utilitarianism:**  Meaning derived from maximizing happiness and minimizing suffering for the greatest number of people.\n",
      "\n",
      "\n",
      "**2. Religious/Spiritual Perspectives:**\n",
      "\n",
      "* **Christianity:** Often centered around serving God and loving others, finding meaning through faith and following religious teachings.\n",
      "* **Islam:**  Meaning derived from submitting to Allah's will and living according to Islamic principles.\n",
      "* **Buddhism:**  Seeking enlightenment and escaping suffering through practices like mindfulness and compassion. \n",
      "* **Hinduism:** Often tied to dharma (righteousness) and achieving moksha (liberation). \n",
      "\n",
      "**3. Personal/Individual Perspectives:**\n",
      "\n",
      "* **Happiness & Fulfillment:**  Simply enjoying the good things in life, pursuing passions, and creating a life you love.\n",
      "* **Love & Connection:** Building strong relationships with family, friends, and community. \n",
      "* **Contribution & Service:** Making a difference in the world through acts of kindness, volunteering, or pursuing a cause you believe in.\n",
      "* **Growth & Learning:** Continuously expanding your knowledge, skills, and perspectives.\n",
      "* **Leaving a Legacy:** Creating something that will outlive you and have a positive impact on the world.\n",
      "* **Simply Being Present:** Appreciating the beauty and wonder of life in the moment. \n",
      "\n",
      "**Ultimately, I think the \"meaning of life\" isn't about *finding* a single meaning. It’s about *creating* one that resonates with you.**\n",
      "\n",
      "**Here are some questions to help you think about your own meaning:**\n",
      "\n",
      "* What values do you want to live by?\n",
      "* What brings you joy and fulfillment?\n",
      "* How can you use your skills and talents to make a positive impact?\n",
      "* What kind of world do you want to create?\n",
      "\n",
      "To help me offer more tailored advice, could you tell me:\n",
      "\n",
      "*   What’s a general area or interest that you're interested in? (e.g., art, science, helping others, travel?)\n",
      "*   Are there any particular philosophies or beliefs that you're drawn to?\n"
     ]
    }
   ],
   "source": [
    "# Create a chat with an initial system prompt.\n",
    "chat = lms.Chat(\"You are a helpfull assistant.\")\n",
    "\n",
    "# Build the chat context by adding messages of relevant types.\n",
    "chat.add_user_message(\"What is the meaning of life?\")\n",
    "\n",
    "prediction_stream = model.respond_stream(chat)\n",
    "\n",
    "for fragment in prediction_stream:\n",
    "    print(fragment.content, end=\"\", flush=True)\n",
    "print() # Advance to a new line at the end of the response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
